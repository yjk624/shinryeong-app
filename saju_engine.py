import json
import pandas as pd
import os
import ephem
import math
from datetime import datetime, timedelta
import pytz
from geopy.geocoders import Nominatim
from timezonefinder import TimezoneFinder

# ==========================================
# 1. ì •ë°€ ì‚¬ì£¼ ê³„ì‚°ê¸° (Astronomical Calculator)
# ==========================================
CHEONGAN = ["ê°‘", "ì„", "ë³‘", "ì •", "ë¬´", "ê¸°", "ê²½", "ì‹ ", "ì„", "ê³„"]
JIJI = ["ì", "ì¶•", "ì¸", "ë¬˜", "ì§„", "ì‚¬", "ì˜¤", "ë¯¸", "ì‹ ", "ìœ ", "ìˆ ", "í•´"]
OHENG_MAP = {
    'ê°‘': 'ëª©', 'ì„': 'ëª©', 'ë³‘': 'í™”', 'ì •': 'í™”', 'ë¬´': 'í† ', 'ê¸°': 'í† ', 
    'ê²½': 'ê¸ˆ', 'ì‹ ': 'ê¸ˆ', 'ì„': 'ìˆ˜', 'ê³„': 'ìˆ˜',
    'ì¸': 'ëª©', 'ë¬˜': 'ëª©', 'ì‚¬': 'í™”', 'ì˜¤': 'í™”', 'ì§„': 'í† ', 'ìˆ ': 'í† ', 'ì¶•': 'í† ', 'ë¯¸': 'í† ',
    'ì‹ ': 'ê¸ˆ', 'ìœ ': 'ê¸ˆ', 'í•´': 'ìˆ˜', 'ì': 'ìˆ˜'
}

def get_location_info(city_name):
    try:
        geolocator = Nominatim(user_agent="shinryeong_app_v3")
        location = geolocator.geocode(city_name)
        if not location: return None
        tf = TimezoneFinder()
        timezone_str = tf.timezone_at(lng=location.longitude, lat=location.latitude)
        return {'lat': location.latitude, 'lon': location.longitude, 'timezone': timezone_str}
    except: return None

def calculate_true_solar_time(birth_dt, lat, lon, timezone_str):
    local_tz = pytz.timezone(timezone_str)
    try: dt_aware = local_tz.localize(birth_dt)
    except ValueError: dt_aware = birth_dt.astimezone(local_tz)
    offset = dt_aware.utcoffset().total_seconds() / 3600
    standard_meridian = offset * 15 
    diff_deg = lon - standard_meridian
    correction_minutes = diff_deg * 4 
    return birth_dt + timedelta(minutes=correction_minutes)

def calculate_saju_pillars(dt):
    y = dt.year
    if dt.month < 2 or (dt.month == 2 and dt.day < 4): year_ganji_idx = (y - 1 - 4) % 60
    else: year_ganji_idx = (y - 4) % 60
    year_stem = CHEONGAN[year_ganji_idx % 10]
    year_branch = JIJI[year_ganji_idx % 12]
    
    month_base_idx = (year_ganji_idx % 10 % 5) * 2 + 2
    month_branch_idx = (dt.month + 10) % 12
    if dt.day < 5: month_branch_idx = (month_branch_idx - 1) % 12
    month_stem = CHEONGAN[(month_base_idx + (month_branch_idx - 2)) % 10]
    month_branch = JIJI[month_branch_idx]

    base_date = datetime(1900, 1, 1)
    diff_days = (dt - base_date).days
    day_ganji_idx = (10 + diff_days) % 60
    day_stem = CHEONGAN[day_ganji_idx % 10]
    day_branch = JIJI[day_ganji_idx % 12]

    hour_base_idx = (day_ganji_idx % 10 % 5) * 2
    h = dt.hour
    hour_branch_idx = 0 if h >= 23 else (h + 1) // 2
    hour_stem = CHEONGAN[(hour_base_idx + hour_branch_idx) % 10]
    hour_branch = JIJI[hour_branch_idx % 12]

    pillars = {'year': f"{year_stem}{year_branch}", 'month': f"{month_stem}{month_branch}", 'day': f"{day_stem}{day_branch}", 'time': f"{hour_stem}{hour_branch}"}
    counts = {'ëª©':0, 'í™”':0, 'í† ':0, 'ê¸ˆ':0, 'ìˆ˜':0}
    for char in [year_stem, year_branch, month_stem, month_branch, day_stem, day_branch, hour_stem, hour_branch]:
        if char in OHENG_MAP: counts[OHENG_MAP[char]] += 1
            
    return {
        'ganji_text': f"{year_stem}{year_branch}ë…„ {month_stem}{month_branch}ì›” {day_stem}{day_branch}ì¼ {hour_stem}{hour_branch}ì‹œ",
        'pillars': pillars, 'day_stem': day_stem, 'day_elem': OHENG_MAP[day_stem],
        'five_elem_counts': counts, 'true_solar_time': dt.strftime("%Y-%m-%d %H:%M")
    }

# ==========================================
# 2. ë°ì´í„°ë² ì´ìŠ¤ ë¡œë” (ê²½ë¡œ ìë™ ì¸ì‹)
# ==========================================
class SajuDB:
    def __init__(self):
        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.db_folder = os.path.join(current_dir, "saju_db")
        self.load_status = {}
        
        self.glossary = self.load_csv('saju_glossary_v2.csv')
        self.five_elements = self.load_json('five_elements_matrix.json')
        self.timeline = self.load_json('timeline_db.json')
        self.shinsal = self.load_json('shinsal_db.json')
        self.love = self.load_json('love_db.json')
        self.health = self.load_json('health_db.json')
        self.career = self.load_json('career_db.json')
        self.symptom = self.load_json('symptom_mapping.json')
        self.compatibility = self.load_json('compatibility_db.json')

    def load_json(self, filename):
        full_path = os.path.join(self.db_folder, filename)
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                self.load_status[filename] = "âœ… Loaded"
                return json.load(f)
        except Exception as e:
            self.load_status[filename] = f"âŒ Error: {e}"
            return {}

    def load_csv(self, filename):
        full_path = os.path.join(self.db_folder, filename)
        try:
            df = pd.read_csv(full_path)
            self.load_status[filename] = "âœ… Loaded"
            return df
        except Exception as e:
            self.load_status[filename] = f"âŒ Error: {e}"
            return pd.DataFrame()

db = SajuDB()

# ==========================================
# 3. ìœ ì—°í•œ ê²€ìƒ‰ ì—”ì§„ (Smart Match Engine)
# ==========================================
def find_in_db(data_dict, keyword):
    """í‚¤ì›Œë“œê°€ í¬í•¨ëœ í‚¤ì˜ ê°’ì„ ë°˜í™˜ (Fuzzy Match)"""
    if not isinstance(data_dict, dict): return None
    if keyword in data_dict: return data_dict[keyword]
    for k, v in data_dict.items():
        if keyword in k: return v
    return None

def _get_data_safe(db_source, primary_key, fallback_keys=[]):
    """
    DBì—ì„œ ë°ì´í„°ë¥¼ êº¼ë‚¼ ë•Œ, í‚¤ê°€ ì—†ìœ¼ë©´ ëŒ€ì²´ í‚¤ë¥¼ ì°¾ê±°ë‚˜
    ì•„ì˜ˆ ë£¨íŠ¸(Root)ì—ì„œ ì°¾ì•„ë³´ëŠ” ì•ˆì „ í•¨ìˆ˜
    """
    # 1. Primary Key ì‹œë„ (ì˜ˆ: imbalance_analysis)
    if primary_key in db_source:
        return db_source[primary_key]
    
    # 2. Fallback Keys ì‹œë„ (ì˜ˆ: imbalance_matrix)
    for k in fallback_keys:
        if k in db_source:
            return db_source[k]
            
    # 3. ëª» ì°¾ì•˜ìœ¼ë©´ í˜¹ì‹œ Root ìì²´ê°€ ë°ì´í„°ì¸ê°€? (ì˜ˆ: ëª©(Wood) í‚¤ê°€ ë°”ë¡œ ìˆëŠ”ì§€ í™•ì¸)
    # ìƒ˜í”Œ í‚¤ì›Œë“œ('ëª©' or 'ê°‘' ë“±)ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ê³  ë§ìœ¼ë©´ í†µì§¸ë¡œ ë°˜í™˜
    sample_keys = ['ëª©', 'í™”', 'í† ', 'ê¸ˆ', 'ìˆ˜', 'Wood', 'Fire', 'ë¹„ê²', 'ì‹ìƒ', '2026', '2025']
    for k in db_source.keys():
        for sample in sample_keys:
            if sample in k:
                return db_source # ìƒì ì—†ì´ ë‚´ìš©ë¬¼ì´ ë°”ë¡œ ìˆëŠ” ê²½ìš°
                
    return {} # ì •ë§ ì—†ìŒ

def analyze_saju_precision(user_data):
    # 1. ì‹œê° ê³„ì‚°
    loc_info = get_location_info(user_data['city'])
    if not loc_info: lat, lon, tz = 37.5665, 126.9780, 'Asia/Seoul'
    else: lat, lon, tz = loc_info['lat'], loc_info['lon'], loc_info['timezone']
    
    birth_dt = datetime(user_data['year'], user_data['month'], user_data['day'], user_data['hour'], user_data['minute'])
    true_dt = calculate_true_solar_time(birth_dt, lat, lon, tz)
    saju = calculate_saju_pillars(true_dt)
    saju['location_info'] = f"{user_data['city']} (ë³´ì •ì‹œê°: {true_dt.strftime('%H:%M')})"
    
    report = {"saju": saju, "analytics": [], "chat_context": []}
    counts = saju['five_elem_counts']
    
    # [ë¶„ì„ 1] ì˜¤í–‰ ê³¼ë‹¤/ê³ ë¦½ (Data Loading ë³´ì • ì ìš©)
    # ìƒì ì´ë¦„ì´ imbalance_analysisì¸ì§€, imbalance_matrixì¸ì§€, ì•„ë‹ˆë©´ ì—†ëŠ”ì§€ í™•ì¸
    imbalance_db = _get_data_safe(db.five_elements, 'imbalance_analysis', ['imbalance_matrix', 'patterns'])
    
    has_imbalance = False
    for elem, count in counts.items():
        found_data = find_in_db(imbalance_db, elem) # "ê¸ˆ"ìœ¼ë¡œ "ê¸ˆ(Metal)" ì°¾ê¸°
        
        if found_data:
            data = None
            tag = ""
            if count >= 3:
                data = found_data.get('excess')
                tag = "ê³¼ë‹¤"
            elif count == 0:
                data = found_data.get('isolation')
                tag = "ë¶€ì¡±"
            
            if data:
                report['analytics'].append({
                    "type": f"âš ï¸ ê¸°ì§ˆ ë¶„ì„ ({tag})",
                    "title": data.get('title', f'{elem} ê¸°ìš´ {tag}'),
                    "content": data.get('shamanic_voice', 'ê¸°ìš´ì´ ì¹˜ìš°ì³ ìˆì–´.')
                })
                report['chat_context'].append(f"{elem} {tag}")
                has_imbalance = True

    if not has_imbalance:
        report['analytics'].append({"type": "âš–ï¸ ì˜¤í–‰ì˜ ì¡°í™”", "title": "ì˜¤í–‰ì´ ê³¨ê³ ë£¨ ê°–ì¶°ì§„ ê·€ê²©", "content": "ì¹˜ìš°ì¹¨ ì—†ì´ ì›ë§Œí•œ ì„±í’ˆì¼ì„¸."})

    # [ë¶„ì„ 2] ì§ì—… (Career) - Data Loading ë³´ì •
    strongest = max(counts, key=counts.get)
    trait_map = {'ëª©':'ì‹ìƒ', 'í™”':'ì¬ì„±', 'í† ':'ë¹„ê²', 'ê¸ˆ':'ê´€ì„±', 'ìˆ˜':'ì¸ì„±'}
    keyword = trait_map.get(strongest, 'ì‹ìƒ')
    
    # career_dbì—ì„œ modern_jobs í‚¤ê°€ ì—†ì–´ë„ ì°¾ë„ë¡ ë³´ì •
    career_data_source = _get_data_safe(db.career, 'modern_jobs', ['jobs', 'career_list'])
    job_data = find_in_db(career_data_source, keyword)
    
    if job_data:
        report['analytics'].append({
            "type": "ğŸ’¼ ì‹ ë ¹ì˜ ì²œì§ ì¶”ì²œ",
            "title": f"'{strongest}' ê¸°ìš´ì„ ì“°ëŠ” ì¼",
            "content": f"**[ì„±í–¥]** {job_data.get('trait', '')}\n\n**[ì¶”ì²œ]** {job_data.get('jobs', '')}\n\nğŸ“¢ {job_data.get('shamanic_voice', '')}"
        })
    else:
        # Fallback
        report['analytics'].append({
             "type": "ğŸ’¼ ì‹ ë ¹ì˜ ì²œì§ ì¶”ì²œ",
             "title": f"'{strongest}' ê¸°ìš´ í™œìš©",
             "content": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì›í™œí•˜ì§€ ì•Šìœ¼ë‚˜, ìë„¤ì˜ ê°•ì ì„ ì‚´ë¦¬ëŠ” ì „ë¬¸ì§ì´ë‚˜ ì‚¬ì—…ì´ ì–´ìš¸ë¦¬ë„¤."
        })

    # [ë¶„ì„ 3] 2026ë…„ ì˜ˆì–¸ (Timeline)
    future_source = _get_data_safe(db.timeline, 'future_flow_db', ['timeline', 'yearly_flow'])
    year_data = find_in_db(future_source, "2026")
    
    if year_data:
        report['analytics'].append({
            "type": "ğŸ”® 2026ë…„ ë³‘ì˜¤ë…„ ì˜ˆì–¸",
            "title": year_data.get('year_title', 'ë‚´ë…„ ìš´ì„¸'),
            "content": f"{year_data.get('summary', '')}\n\n**[ì—¬ë¦„ ê²½ê³ ]** {year_data.get('Q2_Summer', {}).get('shamanic_warning', 'ë§¤ì‚¬ ì¡°ì‹¬í•˜ê²Œ.')}"
        })

    return report

def analyze_compatibility_precision(user_a, user_b):
    res_a = analyze_saju_precision(user_a)
    res_b = analyze_saju_precision(user_b)
    
    report = {
        "saju_a": res_a['saju'], "saju_b": res_b['saju'],
        "analytics": [],
        "chat_context": res_a['chat_context'] + res_b['chat_context']
    }
    
    # ì†ê¶í•©
    stem_a = res_a['saju']['day_elem']
    stem_b = res_b['saju']['day_elem']
    
    # love_db ë¡œë”© ë³´ì •
    comp_db = _get_data_safe(db.love, 'basic_compatibility', ['compatibility'])
    if 'element_harmony' in comp_db: comp_db = comp_db['element_harmony']
    
    eng_map = {'ëª©':'wood', 'í™”':'fire', 'í† ':'earth', 'ê¸ˆ':'metal', 'ìˆ˜':'water'}
    key1 = f"{eng_map[stem_a]}_{eng_map[stem_b]}"
    key2 = f"{eng_map[stem_b]}_{eng_map[stem_a]}"
    
    comp_text = comp_db.get(key1, comp_db.get(key2, ""))
    if not comp_text: comp_text = "ì„œë¡œ ë§ì¶°ê°€ëŠ” í‰ë²”í•œ ì¸ì—°ì¼ì„¸."

    report['analytics'].append({
        "type": "ğŸ’ ì†ê¶í•© ë¶„ì„",
        "title": f"{user_a['name']}({stem_a}) â¤ï¸ {user_b['name']}({stem_b})",
        "content": comp_text
    })
    
    # ê°ˆë“± ì›ì¸
    conflict_db = _get_data_safe(db.love, 'conflict_triggers', ['triggers'])
    if conflict_db:
        # dict values listë¡œ ë³€í™˜
        triggers = list(conflict_db.values())
        if triggers:
            warn = triggers[0] # ëœë¤ ëŒ€ì‹  ì²«ë²ˆì§¸ or ëœë¤
            import random
            warn = random.choice(triggers)
            report['analytics'].append({
                "type": "âš¡ ì´ë³„ ì£¼ì˜ë³´",
                "title": "ì‹¸ì›€ì˜ ì›ì¸",
                "content": f"**[ì´ìœ ]** {warn.get('fight_reason')}\n\nğŸ“¢ {warn.get('shamanic_voice')}"
            })

    return report

def _get_eng(k): return {'ëª©':'Wood','í™”':'Fire','í† ':'Earth','ê¸ˆ':'Metal','ìˆ˜':'Water'}.get(k,'')
