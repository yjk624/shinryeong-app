import streamlit as st
from groq import Groq
from saju_engine import calculate_saju_v3
from datetime import datetime, time
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut, GeocoderServiceError
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import os

# ==========================================
# 1. CONFIGURATION
# ==========================================
st.set_page_config(page_title="ì‹ ë ¹ (Shinryeong)", page_icon="ğŸ”®", layout="centered")

# Robust Geocoding (Increased timeout to 10s to fix "not rendering" issue)
geolocator = Nominatim(user_agent="shinryeong_app_v7_final_fix", timeout=10)

# Initialize Groq
try:
    GROQ_KEY = st.secrets["GROQ_API_KEY"]
    client = Groq(api_key=GROQ_KEY)
except Exception as e:
    st.error(f"ğŸš¨ Connection Error: {e}")
    st.stop()

# Session State
if "messages" not in st.session_state: st.session_state.messages = []
if "saju_context" not in st.session_state: st.session_state.saju_context = ""
if "user_info_logged" not in st.session_state: st.session_state.user_info_logged = False

# ==========================================
# 2. FILE LOADERS
# ==========================================
@st.cache_data
def load_text_file(filename):
    try:
        with open(filename, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

PROMPT_TEXT = load_text_file("prompt.txt")        # The Persona
KNOWLEDGE_TEXT = load_text_file("knowledgebase.txt") # The Brain

# ==========================================
# 3. HELPER FUNCTIONS
# ==========================================
CITY_DB = {
    "ì„œìš¸": (37.56, 126.97), "Seoul": (37.56, 126.97),
    "ë¶€ì‚°": (35.17, 129.07), "Busan": (35.17, 129.07),
    "ì¸ì²œ": (37.45, 126.70), "Incheon": (37.45, 126.70),
    "ëŒ€êµ¬": (35.87, 128.60), "Daegu": (35.87, 128.60),
    "ëŒ€ì „": (36.35, 127.38), "Daejeon": (36.35, 127.38),
    "ê´‘ì£¼": (35.15, 126.85), "Gwangju": (35.15, 126.85),
    "ì œì£¼": (33.49, 126.53), "Jeju": (33.49, 126.53),
    "New York": (40.71, -74.00), "London": (51.50, -0.12)
}

def get_coordinates(city_name):
    clean = city_name.strip()
    # 1. Internal DB Check
    if clean in CITY_DB: return CITY_DB[clean]
    
    # 2. API Check (with error handling)
    try:
        loc = geolocator.geocode(clean)
        if loc: return (loc.latitude, loc.longitude)
    except (GeocoderTimedOut, GeocoderServiceError):
        return None # Return None implies failure, handled in UI
    except Exception as e:
        print(f"Geo Error: {e}")
        return None
    return None

def save_to_database(user_data, birth_date_obj, birth_time_obj, concern):
    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds_dict = dict(st.secrets["gcp_service_account"])
        creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        gs_client = gspread.authorize(creds)
        sheet = gs_client.open("Shinryeong_User_Data").sheet1
        
        row = [
            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            birth_date_obj.strftime("%Y-%m-%d"),
            birth_time_obj.strftime("%H:%M"),
            str(user_data.get('Birth_Place', 'Unknown')),
            user_data.get('Gender', 'Unknown'),
            user_data.get('Year', ''),
            user_data.get('Month', ''),
            user_data.get('Day', ''),
            user_data.get('Time', ''),
            concern
        ]
        sheet.append_row(row)
    except:
        pass

def generate_ai_response(messages):
    try:
        stream = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.6,
            max_tokens=3000, # Increased for full reports
            top_p=1,
            stream=True,
            stop=None,
        )
        full_response = ""
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                content = chunk.choices[0].delta.content
                full_response += content
                # yield content # Streaming disabled for Split Logic consistency
        return full_response
    except Exception as e:
        return f"Error: {e}"

# ==========================================
# 4. UI LAYOUT
# ==========================================
TRANS = {
    "ko": {
        "title": "ğŸ”® ì‹ ë ¹ (Shinryeong)",
        "subtitle": "AI í˜•ì´ìƒí•™ ë¶„ì„ê°€",
        "warning": """
        âš–ï¸ **ë²•ì  ë©´ì±… ì¡°í•­ (Disclaimer):**
        1. ë³¸ ì„œë¹„ìŠ¤ëŠ” ëª…ë¦¬í•™ ë° ìë¯¸ë‘ìˆ˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ **í•™ìˆ ì  ë¶„ì„**ì´ë©°, ì ˆëŒ€ì ì¸ ì˜ˆì–¸ì´ ì•„ë‹™ë‹ˆë‹¤.
        2. ì‹ ë ¹ì€ **ì˜í•™ì  ì§„ë‹¨(Medical Diagnosis)ì´ë‚˜ ë²•ë¥ ì  ì¡°ì–¸(Legal Advice)**ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        3. ë³¸ ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ ì‚¬ìš©ìì˜ ê²°ì •ê³¼ ê·¸ ê²°ê³¼ì— ëŒ€í•œ ì±…ì„ì€ ì „ì ìœ¼ë¡œ **ì‚¬ìš©ì ë³¸ì¸**ì—ê²Œ ìˆìŠµë‹ˆë‹¤.
        """,
        "submit_btn": "ğŸ”® ì‹ ë ¹ì—ê²Œ ë¶„ì„ ìš”ì²­í•˜ê¸°",
        "loading": "â³ ì²œë¬¸ ë°ì´í„°ë¥¼ ê³„ì‚°í•˜ê³  ì‹ ë ¹ì„ ì†Œí™˜í•˜ëŠ” ì¤‘...",
        "geo_error": "âš ï¸ ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì„œë²„ ê³¼ë¶€í•˜ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ 'ì„œìš¸'ë¡œ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”).",
        "chat_placeholder": "ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?",
        "reset_btn": "ğŸ”„ ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘",
        "dob_label": "ìƒë…„ì›”ì¼", "time_label": "íƒœì–´ë‚œ ì‹œê°„", "gender_label": "ì„±ë³„",
        "male": "ë‚¨ì„±", "female": "ì—¬ì„±", "loc_label": "íƒœì–´ë‚œ ì§€ì—­ (ë„ì‹œëª…)",
        "concern_label": "í˜„ì¬ ê°€ì¥ í° ê³ ë¯¼ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "theory_header": "ğŸ“š ë¶„ì„ ê·¼ê±° ë° ê¸°ìˆ ì  ì´ë¡  (Technical Basis)"
    },
    "en": {
        "title": "ğŸ”® Shinryeong",
        "subtitle": "AI Metaphysical Analyst",
        "warning": """
        âš–ï¸ **Legal Disclaimer:**
        1. This service provides **academic analysis** based on Saju and Jami Dou Shu data; it is not absolute prophecy.
        2. Shinryeong does **NOT provide Medical Diagnoses or Legal Advice**.
        3. The user bears full responsibility for any decisions made based on this analysis.
        """,
        "submit_btn": "ğŸ”® Request Analysis",
        "loading": "â³ Calculating celestial data...",
        "geo_error": "âš ï¸ Location not found. Please try a major city.",
        "chat_placeholder": "Do you have follow-up questions?",
        "reset_btn": "ğŸ”„ Start New Analysis",
        "dob_label": "Date of Birth", "time_label": "Time of Birth", "gender_label": "Gender",
        "male": "Male", "female": "Female", "loc_label": "Birth Place (City)",
        "concern_label": "What is your main concern?",
        "theory_header": "ğŸ“š Technical Theory & Basis"
    }
}

with st.sidebar:
    lang_code = "ko" if st.radio("Language / ì–¸ì–´", ["í•œêµ­ì–´", "English"]) == "í•œêµ­ì–´" else "en"
    txt = TRANS[lang_code]
    if st.button(txt["reset_btn"]):
        st.session_state.messages = []
        st.session_state.saju_context = ""
        st.session_state.user_info_logged = False
        st.rerun()
    st.caption("Engine: Groq Llama-3.3")

st.title(txt["title"])
st.caption(txt["subtitle"])
st.info(txt["warning"])

# ==========================================
# 5. APP LOGIC
# ==========================================
if not st.session_state.saju_context:
    with st.form("input"):
        col1, col2 = st.columns(2)
        with col1:
            b_date = st.date_input(txt["dob_label"], min_value=datetime(1940,1,1))
            b_time = st.time_input(txt["time_label"], value=time(12,00), step=60)
        with col2:
            gender = st.radio(txt["gender_label"], [txt["male"], txt["female"]])
            loc_in = st.text_input(txt["loc_label"], placeholder="Seoul, New York...")
        q = st.text_area(txt["concern_label"], height=100)
        submitted = st.form_submit_button(txt["submit_btn"])

    if submitted:
        if not loc_in:
            st.error(txt["geo_error"])
        else:
            with st.spinner(txt["loading"]):
                coords = get_coordinates(loc_in)
                if coords:
                    lat, lon = coords
                    saju = calculate_saju_v3(b_date.year, b_date.month, b_date.day, b_time.hour, b_time.minute, lat, lon)
                    saju['Birth_Place'] = loc_in
                    saju['Gender'] = gender
                    
                    # [CRITICAL] 1. Enforce Language 2. Enforce Structure 3. Inject Persona
                    system_prompt = f"""
                    [SYSTEM ROLE]
                    You are 'Shinryeong'. Act EXACTLY according to the Persona below.
                    {PROMPT_TEXT}
                    
                    [KNOWLEDGE BASE]
                    Use these rules for analysis:
                    {KNOWLEDGE_TEXT}
                    
                    [USER DATA]
                    - Saju: {saju}
                    - Gender: {gender}
                    - Location: {loc_in}
                    
                    [STRICT OUTPUT RULES]
                    1. LANGUAGE: Respond in {lang_code.upper()} ({'Korean' if lang_code == 'ko' else 'English'}). 
                       - Even if the user asks in English, if the setting is Korean, answer in Korean.
                    2. STRUCTURE: 
                       - First, provide the Counseling/Advice (Persona).
                       - Then, print EXACTLY: "[[TECHNICAL_SECTION]]"
                       - Finally, provide the Technical Theory/Basis (Explain the Ten Gods, Elements used).
                    """
                    
                    st.session_state.saju_context = system_prompt
                    
                    msgs = [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": f"My concern is: {q}. Please analyze."}
                    ]
                    
                    # Call AI (No streaming to handle split)
                    full_text = generate_ai_response(msgs)
                    
                    # Split Response
                    if "[[TECHNICAL_SECTION]]" in full_text:
                        parts = full_text.split("[[TECHNICAL_SECTION]]")
                        main_report = parts[0]
                        theory_report = parts[1]
                    else:
                        main_report = full_text
                        theory_report = "Technical basis integrated into main text."

                    # Store & Display
                    st.session_state.messages.append({"role": "user", "content": q})
                    st.session_state.messages.append({"role": "assistant", "content": main_report, "theory": theory_report})
                    
                    if not st.session_state.user_info_logged:
                        save_to_database(saju, b_date, b_time, q)
                        st.session_state.user_info_logged = True
                    st.rerun()
                else:
                    st.error(txt["geo_error"])
else:
    st.markdown("---")
    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])
            # [FIXED] Show theory in expander if available for this message
            if "theory" in m:
                with st.expander(txt["theory_header"]):
                    st.markdown(m["theory"])
            
    if p := st.chat_input(txt["chat_placeholder"]):
        st.session_state.messages.append({"role": "user", "content": p})
        with st.chat_message("user"): st.markdown(p)
        
        # Build context for next turn
        groq_msgs = [{"role": "system", "content": st.session_state.saju_context}]
        # Only feed the 'content' (main text) back to AI, not the theory, to keep context clean
        for m in st.session_state.messages:
            groq_msgs.append({"role": m["role"], "content": m["content"]})
            
        with st.chat_message("assistant"):
            with st.spinner("..."):
                response_text = generate_ai_response(groq_msgs)
                
                # Dynamic Split for Chat as well
                if "[[TECHNICAL_SECTION]]" in response_text:
                    parts = response_text.split("[[TECHNICAL_SECTION]]")
                    main_r = parts[0]
                    theory_r = parts[1]
                else:
                    main_r = response_text
                    theory_r = "Analysis based on established Saju logic."
                
                st.markdown(main_r)
                with st.expander(txt["theory_header"]):
                    st.markdown(theory_r)
                    
                st.session_state.messages.append({"role": "assistant", "content": main_r, "theory": theory_r})
